<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>b07512b7fe424aa29c258814d00a8dd5</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell code" data-execution_count="1" id="a92nHELU1gxI">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>For data analysis and machine learning, this code imports several
libraries and modules.</p>
<p>Math, numpy, pandas, and matplotlib.pyplot are imported in the first
four lines. These libraries provide functions and tools for mathematical
calculations, numerical operations, data manipulation, and data
visualization, respectively. Tensorflow and Sklearn.metrics are imported
next. Machine learning models can be built and trained using TensorFlow,
while sklearn.metrics offers functions for evaluating the performance of
machine learning models, including the calculation of mean squared
errors and mean absolute errors.</p>
<p>The last line imports the warnings module and sets a filter to ignore
warning messages. This is done to suppress any warning messages that may
be generated during the execution of the code. Overall, this code sets
up the necessary dependencies for performing data analysis and machine
learning tasks.</p>
</div>
<div class="cell code" data-execution_count="2" id="cniPewwH16-t">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>AAPL <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/drive/MyDrive/Database/Pre_Processed_AAPL.csv&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>TSLA <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/drive/MyDrive/Database/Pre_Processed_TSLA.csv&quot;</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>GOOG <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/drive/MyDrive/Database/Pre_Processed_GOOG.csv&quot;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>MSFT <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/drive/MyDrive/Database/Pre_Processed_MSFT.csv&quot;</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>AMZN <span class="op">=</span> pd.read_csv(<span class="st">&quot;/content/drive/MyDrive/Database/Pre_Processed_AMZN.csv&quot;</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>AAPL, TSLA, GOOG, MSFT, and AMZN are read and loaded into separate
variables. Every CSV file contains pre-processed data related to
different stocks (Apple, Tesla, Google, Microsoft, and Amazon,
respectively). The CSV files are read using the PD.read_csv() function.
File paths indicate the location of the CSV files on the Google Drive
("/content/drive/MyDrive/Database/Pre_Processed_*.csv"). By using this
function, the code reads the contents of each CSV file and stores it in
the respective variable. As a result, the variables AAPL, TSLA, GOOG,
MSFT, and AMZN will contain the data from their corresponding CSV files.
As a result, each company's stock data can be further manipulated,
analyzed, or modeled separately.</p>
</div>
<section id="data-processing" class="cell markdown" id="vDdZr0DH0sor">
<h3>Data Processing</h3>
</section>
<div class="cell code" data-execution_count="3" id="kkZs6LC9QPMp">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Dataset(Data, Date):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  Train_Data <span class="op">=</span> Data[<span class="st">&#39;Adj. Close&#39;</span>][Data[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> Date].to_numpy()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  Data_Train <span class="op">=</span> []</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  Data_Train_X <span class="op">=</span> []</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  Data_Train_Y <span class="op">=</span> []</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(Train_Data), <span class="dv">5</span>):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>      Data_Train.append(Train_Data[i : i <span class="op">+</span> <span class="dv">5</span>])</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>      <span class="cf">pass</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(Data_Train[<span class="op">-</span><span class="dv">1</span>]) <span class="op">&lt;</span> <span class="dv">5</span>:</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    Data_Train.pop(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  Data_Train_X <span class="op">=</span> Data_Train[<span class="dv">0</span> : <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  Data_Train_X <span class="op">=</span> np.array(Data_Train_X)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  Data_Train_X <span class="op">=</span> Data_Train_X.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  Data_Train_Y <span class="op">=</span> Data_Train[<span class="dv">1</span> : <span class="bu">len</span>(Data_Train)]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  Data_Train_Y <span class="op">=</span> np.array(Data_Train_Y)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  Data_Train_Y <span class="op">=</span> Data_Train_Y.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  Test_Data <span class="op">=</span> Data[<span class="st">&#39;Adj. Close&#39;</span>][Data[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> Date].to_numpy()</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  Data_Test <span class="op">=</span> []</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  Data_Test_X <span class="op">=</span> []</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>  Data_Test_Y <span class="op">=</span> []</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(Test_Data), <span class="dv">5</span>):</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>      Data_Test.append(Test_Data[i : i <span class="op">+</span> <span class="dv">5</span>])</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span>:</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>      <span class="cf">pass</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(Data_Test[<span class="op">-</span><span class="dv">1</span>]) <span class="op">&lt;</span> <span class="dv">5</span>:</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    Data_Test.pop(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>  Data_Test_X <span class="op">=</span> Data_Test[<span class="dv">0</span> : <span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>  Data_Test_X <span class="op">=</span> np.array(Data_Test_X)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>  Data_Test_X <span class="op">=</span> Data_Test_X.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>  Data_Test_Y <span class="op">=</span> Data_Test[<span class="dv">1</span> : <span class="bu">len</span>(Data_Test)]</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>  Data_Test_Y <span class="op">=</span> np.array(Data_Test_Y)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>  Data_Test_Y <span class="op">=</span> Data_Test_Y.reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>))</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> Data_Train_X, Data_Train_Y, Data_Test_X, Data_Test_Y</span></code></pre></div>
</div>
<div class="cell markdown">
<p>The code defines a function named <code>Dataset</code> that takes two
parameters: <code>Data</code> and <code>Date</code>. The purpose of this
function is to preprocess a given dataset and split it into training and
testing sets based on a specified date. First, it extracts the 'Adj.
Delete the 'Close' column from the <code>Data</code> DataFrame for the
dates before the specified <code>Date</code>. It converts the extracted
data into a NumPy array and assigns it to the <code>Train_Data</code>
variable. Data_Train, Data_Train_X, and Data_Train_Y variables are then
initialized. After that, it iterates over the <code>Train_Data</code>
array in increments of 5, creating subsets of 5 consecutive values.
These subsets are appended to the <code>Data_Train</code> list.</p>
<p>If the length of the last subset in <code>Data_Train</code> is less
than 5 (due to incomplete data), it is removed from the list using the
<code>pop()</code> function.</p>
<p>The next set of operations is similar to the previous steps, but it
applies to the testing data. 'Adj.' An array is created using the Close
column from the SDataDataFrame, and the result is assigned to the
TestData variable. Subsets of five consecutive values are then created
and appended to the <code>Data_Test</code> list. The last subset is
removed if its length is less than 5. Finally, the collected training
and testing data are reshaped into a three-dimensional NumPy array of
shape (batch_size, sequence_length, input_dimension). The training data
arrays are assigned to <code>Data_Train_X</code> and
<code>Data_Train_Y</code>, while the testing data arrays are assigned to
<code>Data_Test_X</code> and <code>Data_Test_Y</code>. These arrays are
returned by the function: <code>Data_Train_X</code>,
<code>Data_Train_Y</code>, <code>Data_Test_X</code>, and
<code>Data_Test_Y</code>. The arrays can be used for further analysis or
modeling, such as time series analysis or sequence prediction.</p>
</div>
<div class="cell markdown" id="fFmGO6j50wbO">
<p>The model number is ###</p>
</div>
<div class="cell code" data-execution_count="4" id="DPWMIKGv_7b1">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Model():</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  model <span class="op">=</span> tf.keras.models.Sequential([</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                                      tf.keras.layers.LSTM(<span class="dv">200</span>, input_shape <span class="op">=</span> (<span class="dv">5</span>, <span class="dv">1</span>), activation <span class="op">=</span> tf.nn.leaky_relu, return_sequences <span class="op">=</span> <span class="va">True</span>),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                                      tf.keras.layers.LSTM(<span class="dv">200</span>, activation <span class="op">=</span> tf.nn.leaky_relu),</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>                                      tf.keras.layers.Dense(<span class="dv">200</span>, activation <span class="op">=</span> tf.nn.leaky_relu),</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>                                      tf.keras.layers.Dense(<span class="dv">100</span>, activation <span class="op">=</span> tf.nn.leaky_relu),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>                                      tf.keras.layers.Dense(<span class="dv">50</span>, activation <span class="op">=</span> tf.nn.leaky_relu),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                                      tf.keras.layers.Dense(<span class="dv">5</span>, activation <span class="op">=</span> tf.nn.leaky_relu)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                                      ])</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> model</span></code></pre></div>
</div>
<div class="cell markdown">
<p>Code in this file defines a function named <code>Model</code> that
constructs and returns a specific type of machine learning model. The
model is built using the TensorFlow library and follows a sequential
architecture. There are several layers in the model. With 200 units, the
first layer is an LSTM (Long Short-Term Memory). The input shape of this
layer is (5, 1), indicating that it expects input sequences with a
length of 5 and a feature dimension of 1. The activation function used
in this layer is a leaky ReLU (Rectified Linear Unit), which introduces
a small gradient for negative input values. A 200-unit LSTM layer
follows. The leaky ReLU activation function is also used. Unlike the
previous layer, this layer does not have the
<code>return_sequences</code> argument set to True. This means that it
only returns the final output of the LSTM layer rather than the full
sequence of outputs. The LSTM layer is followed by several dense layers.
Each neuron in these layers is connected to every neuron in the previous
layer. Different dense layers have different numbers of units: 200, 100,
50, and 5. Each dense layer uses the leaky ReLU activation function.
Layers are stacked sequentially, with the output of one layer serving as
the input for the next. The model is then returned by the function. By
using this function, the specific model configuration can be created and
obtained. Based on the data and the specific problem, the returned model
can be used for regression, classification, or sequence prediction.</p>
</div>
<div class="cell code" data-execution_count="5" id="k-zXwjAyrGm7">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>It creates an instance of the machine learning model defined by the
<code>Model</code> function. The <code>Model</code> function constructs
and configures the model architecture using TensorFlow, and this line
assigns the constructed model to the variable <code>model</code>.</p>
<p>By calling the <code>Model()</code> function, the code instantiates
the model object, which can be further utilized for training,
evaluation, and prediction tasks. The model contains the layers and
parameters defined in the <code>Model</code> function, such as LSTM
layers, dense layers, and activation functions.</p>
<p>Once this line of code is executed, the <code>model</code> variable
holds the constructed model, and it can be employed to train on data,
make predictions, evaluate performance, and perform other operations
associated with the machine learning model.</p>
</div>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:754}"
id="RAS71VonrLzU" data-outputId="18166993-ab89-4ce0-84ea-f367714824db">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>tf.keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="6">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/7bcdf71a1e772c59232a64c27e565c19f992b116.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>Using the TensorFlow Keras library's plot_model function, this code
generates a visual representation of the machine learning model. The
function takes the <code>model</code> object as input and generates a
graphical diagram that illustrates the structure of the model. This
provides a visual overview of the model layers and their relationships.
Layers are represented as blocks, and data flow is indicated by arrows
between the blocks. The plot includes details such as the layer types,
shapes of inputs and outputs, and the connections between layers.
Show_shapes=True displays the input and output tensor shapes. This
information can be helpful in understanding the dimensions and flow of
data through the model. Using this model plot, it is easier to visualize
and comprehend the structure of the machine learning model. As a result
of this visual representation, it is easier to understand the model's
design, identify any potential issues or improvements, and communicate
the model architecture to those involved in the development or review of
the model.</p>
</div>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="neXmHN79rO0k" data-outputId="307f6638-11fe-4ad2-c5bb-51fe1611d996">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 5, 200)            161600    
_________________________________________________________________
lstm_1 (LSTM)                (None, 200)               320800    
_________________________________________________________________
dense (Dense)                (None, 200)               40200     
_________________________________________________________________
dense_1 (Dense)              (None, 100)               20100     
_________________________________________________________________
dense_2 (Dense)              (None, 50)                5050      
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 255       
=================================================================
Total params: 548,005
Trainable params: 548,005
Non-trainable params: 0
_________________________________________________________________
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>In this line of code, the architecture and parameters of the machine
learning model are summarized. The <code>summary()</code> method is a
function provided by TensorFlow's Keras library that generates a concise
overview of the model.</p>
<p>When executed, this code displays information about each layer in the
model, such as the layer type, output shape, number of parameters, and
number of trainable parameters. The summary also includes the total
number of parameters in the model. This provides a high-level
understanding of the model's structure. It helps in assessing the number
of layers, the size of the input and output tensors, and the total
number of parameters that need to be learned during training. Using this
information, model evaluation and debugging can be accomplished. It
allows you to quickly check if the model is configured as intended,
verify that the input and output shapes match the data requirements, and
get insights into the complexity of the model in terms of trainable
parameters.</p>
<p>The machine learning model summary provides a comprehensive overview
of its structure and characteristics. Further analysis, optimization,
and interpretation of the model's performance can be guided by this
information.</p>
</div>
<section id="rates-for-customized-learning" class="cell markdown"
id="vJDxyTC40zmg">
<h3>Rates for Customized Learning</h3>
</section>
<div class="cell code" data-execution_count="8" id="vLjevQLkiIoP">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> scheduler(epoch):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> epoch <span class="op">&lt;=</span> <span class="dv">150</span>:</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    lrate <span class="op">=</span> (<span class="dv">10</span> <span class="op">**</span> <span class="op">-</span><span class="dv">5</span>) <span class="op">*</span> (epoch <span class="op">/</span> <span class="dv">150</span>) </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> epoch <span class="op">&lt;=</span> <span class="dv">400</span>:</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    initial_lrate <span class="op">=</span> (<span class="dv">10</span> <span class="op">**</span> <span class="op">-</span><span class="dv">5</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    lrate <span class="op">=</span> initial_lrate <span class="op">*</span> math.exp(<span class="op">-</span>k <span class="op">*</span> (epoch <span class="op">-</span> <span class="dv">150</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    lrate <span class="op">=</span> (<span class="dv">10</span> <span class="op">**</span> <span class="op">-</span><span class="dv">6</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> lrate</span></code></pre></div>
</div>
<div class="cell markdown">
<p>The code defines a function named "scheduler" that takes an epoch
parameter as its input. The purpose of this function is to adjust and
return the learning rate (lrate) based on the value of the epoch. This
is done by checking the value of the epoch parameter. A fraction of a
hundred is used to calculate the learning rate below or equal to 150,
with the fraction increasing as the epoch progresses. This means that
the learning rate starts small and gradually increases over the initial
epochs. A different formula is used if the epoch is greater than 150 but
less than or equal to 400. The initial learning rate is set to 10^-5,
and the rate exponentially decreases with the epoch value. The decay
rate is controlled by the constant <code>k</code> and is used to
gradually reduce the learning rate over time. When the epoch is greater
than 400, the learning rate is fixed at 10^-6. This means that after 400
epochs, the learning rate remains constant at a very low value. The
calculated learning rate is returned as the output of the function. With
this function, the learning rate is dynamically adjusted during
training. In this function, a varying learning rate schedule is defined
based on the progress of the training epochs. By adapting the learning
rate to the characteristics of the optimization problem, dynamic
learning rate schedules can improve the performance and convergence of
machine learning models.</p>
</div>
<div class="cell code" data-execution_count="9"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:293}"
id="H5Aoh-QGiLh-" data-outputId="0d26ee6d-1c08-40fb-c73d-9680afab6ba1">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> [i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">1001</span>, <span class="dv">1</span>)]</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>lrate <span class="op">=</span> [scheduler(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">1001</span>, <span class="dv">1</span>)]</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>plt.plot(epochs, lrate)</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">
<pre><code>[&lt;matplotlib.lines.Line2D at 0x7f9688b03150&gt;]</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/69151958413915e63a7614523a581a392d8b02cb.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>A plot of learning rate values over a range of epochs is generated by
this code.</p>
<p>With a step size of 1, the first line of code creates a list of
epochs containing values from 1 to 1000 (inclusive). This list
represents the range of epochs for which the learning rate will be
calculated. It is created by applying the scheduler function to each
value in the <code>epochs</code> list. A scheduler function calculates
the learning rate based on the value of the epoch. Thus, the
<code>lrate</code> list contains the corresponding learning rate values
for each epoch in the <code>epochs</code> list. To create a line plot,
the third line of code calls the plt.plot() function from
matplotlib.pyplot. The x-axis values are taken from the epochs list and
the y-axis values are taken from the lrate list. This generates a line
graph that illustrates how the learning rate changes over the range of
epochs. The learning rate values are plotted against the corresponding
epochs to provide a visual representation of how the learning rate
changes. Understanding how the learning rate schedule affects the
model's performance and convergence can be helpful. For improved model
training, it allows for analysis and fine-tuning of the learning rate
strategy.</p>
</div>
<div class="cell code" data-execution_count="10" id="R0NG_mhJiQH_">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>callback <span class="op">=</span> tf.keras.callbacks.LearningRateScheduler(scheduler)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>An object named "callback" is created in this line of code that
utilizes a learning rate scheduler during the training process.</p>
<p>Callback objects are constructed using the
tf.keras.callbacks.LearningRateScheduler() function. The scheduler
function is passed as an argument. The <code>scheduler</code> function
determines the learning rate based on the epoch number. A callback
object is passed to the model's training routine, such as fit(). The
callback is responsible for modifying the learning rate of the model at
specific intervals, as defined by the <code>scheduler</code> function.
An epoch-based learning rate scheduler adjusts the learning rate
dynamically during training. Adapting the learning rate to the changing
requirements of the model as it goes through different stages of
optimization can be beneficial for improving the training process. Using
the learning rate scheduler callback, the model can adjust its learning
rate automatically and without manual intervention. A better model
convergence, faster training, and better performance can be achieved as
a result.</p>
</div>
<div class="cell markdown" id="P9l6y-jBQL-G">
<p>The apple</p>
</div>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:195}"
id="thrQ_-6x7_7m" data-outputId="95ad792e-1c99-4e80-b987-9ca65ffe5fac">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>AAPL.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="11">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj. Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2015-01-02</td>
      <td>27.85</td>
      <td>27.86</td>
      <td>26.84</td>
      <td>27.33</td>
      <td>24.86</td>
      <td>212818400.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2015-01-05</td>
      <td>27.07</td>
      <td>27.16</td>
      <td>26.35</td>
      <td>26.56</td>
      <td>24.16</td>
      <td>257142000.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2015-01-06</td>
      <td>26.64</td>
      <td>26.86</td>
      <td>26.16</td>
      <td>26.57</td>
      <td>24.16</td>
      <td>263188400.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2015-01-07</td>
      <td>26.80</td>
      <td>27.05</td>
      <td>26.67</td>
      <td>26.94</td>
      <td>24.50</td>
      <td>160423600.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2015-01-08</td>
      <td>27.31</td>
      <td>28.04</td>
      <td>27.17</td>
      <td>27.97</td>
      <td>25.44</td>
      <td>237458000.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>Displays the first few rows of the AAPL DataFrame. The
<code>.head()</code> function is a method provided by the pandas library
that allows us to inspect the top portion of a DataFrame. This code
prints the first few columns of the AAPL DataFrame. By default, it
displays the first five rows, but this can be customized by passing a
specific number as an argument to the <code>.head()</code> function. It
is used to quickly view the data in the AAPL DataFrame. By inspecting
the top rows, we can examine the column names and the values in the
dataset, which helps in understanding the structure and content of the
data. We can use this information for data exploration, data cleaning,
and gaining an initial understanding of the data. In addition to
allowing us to verify if the data is loaded correctly, it provides a
glimpse into the AAPL DataFrame's format and content.</p>
</div>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="IA_pY7CN8B0x" data-outputId="41684e67-b44b-4a2b-f80a-122356808927">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>AAPL.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1549 entries, 0 to 1548
Data columns (total 7 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   Date        1549 non-null   object 
 1   Open        1549 non-null   float64
 2   High        1549 non-null   float64
 3   Low         1549 non-null   float64
 4   Close       1549 non-null   float64
 5   Adj. Close  1549 non-null   float64
 6   Volume      1549 non-null   float64
dtypes: float64(6), object(1)
memory usage: 84.8+ KB
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>AAPL DataFrame summary information is provided by this code. This
method in the pandas library displays a concise summary of the structure
and contents of a DataFrame. The code displays information about the
AAPL DataFrame when executed, including the column names, the number of
non-null values in each column, and the column types. Additionally, it
provides an overall summary that includes the total number of entries
(rows) in the DataFrame. This function provides an overview of the
dataset's structure and characteristics. It helps in understanding the
data types of each column, identifying missing or null values, and
estimating the memory usage of the DataFrame. Data exploration, data
cleaning, and initial data analysis make use of this information. It
allows us to assess the quality and completeness of the data, determine
if any data type conversions or missing value handling is necessary, and
make informed decisions regarding further data processing or
analysis.</p>
<p>By using <code>.info()</code>, we gain insights into the basic
properties of the AAPL DataFrame, enabling us to proceed with subsequent
data manipulations and analysis with a clearer understanding of the
data's composition.</p>
</div>
<div class="cell code" data-execution_count="13" id="elqcyE_H3h2S">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change Dtype of Date column</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>AAPL[<span class="st">&quot;Date&quot;</span>] <span class="op">=</span> pd.to_datetime(AAPL[<span class="st">&quot;Date&quot;</span>])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code converts the data type of the "Date" column in the AAPL
DataFrame to the datetime format using the <code>pd.to_datetime()</code>
function provided by the pandas library.</p>
<p>The "Date" column in the AAPL DataFrame is converted into a datetime
format by executing this code. The datetime format is a standardized
representation of dates and times that allows for easier manipulation
and analysis of temporal data. This function converts the "Date" column
to the datetime format. It ensures that the "Date" column is interpreted
as a date, not just a number or text. By changing the data type of the
"Date" column to datetime, you can filter or sort the DataFrame
according to dates, extract specific components from the dates (year,
month, day), calculate time differences, and perform time-based
analyses. As a result of this code, the "Date" column in the AAPL
DataFrame is recognized as datetime data, enabling The dataset can
handle and utilize temporal information seamlessly.</p>
</div>
<div class="cell markdown" id="FPawFX7U5VVz">
<p>Split the Data into Training and Test set. The Training Period:
2015-01-02 - 2020-09-30 and the Testing Period: 2020-10-01 -
2021-02-26.</p>
</div>
<div class="cell code" data-execution_count="14" id="Cdu0-_N238N2">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>AAPL_Date <span class="op">=</span> <span class="st">&#39;2020-10-01&#39;</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>AAPL_Train_X, AAPL_Train_Y, AAPL_Test_X, AAPL_Test_Y <span class="op">=</span> Dataset(AAPL, AAPL_Date)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code assigns values to variables and calls the
<code>Dataset</code> function to split the AAPL dataset into training
and testing sets based on a specified date. In the first line, the
variable 'AAPL_Date' is assigned the value '2020-10-01'. The second line
of code calls the Dataset() function with the AAPL dataset and the
<code>AAPL_Date</code> as arguments. The <code>Dataset</code> function
is responsible for performing the actual splitting of the data. The
<code>Dataset</code> function takes the AAPL dataset and the
<code>AAPL_Date</code> as inputs and returns four sets of data:
<code>AAPL_Train_X</code>, <code>AAPL_Train_Y</code>,
<code>AAPL_Test_X</code>, and <code>AAPL_Test_Y</code>.
<code>AAPL_Train_X</code> and <code>AAPL_Train_Y</code> represent the
training data, where <code>AAPL_Train_X</code> contains the input
features and <code>AAPL_Train_Y</code> contains the corresponding output
labels or target values. <code>AAPL_Test_X</code> and
<code>AAPL_Test_Y</code> represent the testing data, where
<code>AAPL_Test_X</code> contains the input features for testing and
<code>AAPL_Test_Y</code> contains the corresponding expected output
labels or target values for evaluation. By calling the
<code>Dataset</code> function and assigning the returned values to
specific variables, this code organizes the AAPL dataset into separate
training and testing sets, which can be further used for training a
machine learning model, evaluating its performance, or conducting any
other analysis related to the dataset.</p>
</div>
<section id="fitting-the-model" class="cell markdown" id="WhsAWnFP1-_t">
<h3>Fitting the model</h3>
</section>
<div class="cell code" data-execution_count="15" id="yMBW7DTXAOo6">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>AAPL_Model <span class="op">=</span> Model()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>For the AAPL dataset, this code creates a machine learning model
instance.</p>
<p>This line of code initializes the variable AAPL_Model and assigns its
value to the Model() function. The <code>Model()</code> function is
responsible for constructing and configuring the specific machine
learning model architecture.</p>
<p>By calling the <code>Model()</code> function, the code instantiates
the <code>AAPL_Model</code> object, which represents the machine
learning model tailored for the AAPL dataset.</p>
<p>The <code>AAPL_Model</code> object encapsulates the architecture,
parameters, and functionality defined within the <code>Model()</code>
function. It can be utilized to perform various tasks, such as training
the model on the AAPL training data, making predictions, evaluating the
model's performance, or conducting any other operations associated with
the machine learning model.</p>
<p>Overall, this code sets up the <code>AAPL_Model</code> object as an
instance of the machine learning model specific to the AAPL dataset,
enabling further utilization of the model for analysis, prediction, and
other tasks related to the AAPL stock data.</p>
</div>
<div class="cell code" data-execution_count="16" id="YIN5tmbx9Pz5">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>AAPL_Model.<span class="bu">compile</span>(optimizer <span class="op">=</span> tf.keras.optimizers.Adam(), loss <span class="op">=</span> <span class="st">&#39;mse&#39;</span>, metrics <span class="op">=</span> tf.keras.metrics.RootMeanSquaredError())</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code configures the compilation settings for the
<code>AAPL_Model</code> machine learning model. This code is provided by
the TensorFlow Keras library's compile() function. It takes several
arguments to define the optimizer, loss function, and metrics to be used
during the training process. The optimizer argument is set to Adam in
this example. The optimizer determines how the model's weights are
updated during training, and Adam is a popular optimization algorithm
widely used in deep learning. A mse loss argument is used. It is clear
from this that the mean square error is the loss function used to
calculate the difference between the predicted and real outputs.</p>
<p>The <code>metrics</code> argument is set to
<code>tf.keras.metrics.RootMeanSquaredError()</code>, which initializes
the root mean squared error (RMSE) as the evaluation metric. The RMSE
metric provides a measure of how well the model performs in terms of the
average difference between the predicted and true outputs.</p>
<p>By configuring these settings through the <code>compile()</code>
function, the code prepares the <code>AAPL_Model</code> for the training
process, specifying the optimization algorithm, loss function, and
evaluation metric to be used. In order to train the model effectively
and assess its performance accurately, these settings are crucial.</p>
</div>
<div class="cell code" id="BNxXmS48BxEb">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>AAPL_hist <span class="op">=</span> AAPL_Model.fit(AAPL_Train_X, AAPL_Train_Y, epochs <span class="op">=</span> <span class="dv">1000</span>, validation_data <span class="op">=</span> (AAPL_Test_X, AAPL_Test_Y), callbacks<span class="op">=</span>[callback])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code trains the <code>AAPL_Model</code> machine learning model
using the training data (<code>AAPL_Train_X</code> and
<code>AAPL_Train_Y</code>) and evaluates its performance on the testing
data (<code>AAPL_Test_X</code> and <code>AAPL_Test_Y</code>).</p>
<p>The <code>fit()</code> method is a function provided by the
TensorFlow Keras library that performs the training process for a
machine learning model. It takes several arguments to specify the
training data, the number of training epochs, the validation data for
evaluation, and any additional callbacks to be utilized during
training.</p>
<p>In this specific code, <code>AAPL_Train_X</code> and
<code>AAPL_Train_Y</code> are passed as the training data, representing
the input features and the corresponding output labels,
respectively.</p>
<p>The <code>epochs</code> argument is set to 1000, indicating the
number of times the training data will be iterated over during the
training process. Each epoch represents a complete pass through the
entire training dataset. In this case, validation data is set to
(AAPL_Test_X, AAPL_Test_Y), providing the testing data as a validation
set. This allows for monitoring the model's performance on unseen data
and helps in assessing its generalization ability. The callbacks
argument refers to a callback object (such as a learning rate
scheduler). Callbacks provide additional functionalities during
training, such as modifying the learning rate or saving the model's
checkpoints. AAPL_Model is trained using the specified training data and
settings by running the code above. The model's performance is evaluated
on the testing data after each epoch, and the training history is stored
in the <code>AAPL_hist</code> object, which can be used to analyze the
model's training progress and performance metrics.</p>
<p>Overall, this code initiates and manages the training process for the
<code>AAPL_Model</code>, allowing it to learn from the training data and
improve its performance over the specified number of epochs.</p>
</div>
<div class="cell code" data-execution_count="18" id="GI_rlBQ4HBim">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>history_dict <span class="op">=</span> AAPL_hist.history</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history_dict[<span class="st">&quot;loss&quot;</span>]</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;root_mean_squared_error&quot;</span>]</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history_dict[<span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>val_root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;val_root_mean_squared_error&quot;</span>]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>A training history is obtained after the training process has been
completed by this code. It captures the values of different metrics
recorded during training and organizes them into separate variables for
further analysis and visualization. In the first line of code, the
history of the AAPL model is stored in the history_dict variable. The
<code>history</code> attribute of the <code>AAPL_hist</code> object
contains various recorded metrics such as loss, root mean squared error
(RMSE), validation loss, and validation RMSE. The subsequent lines of
code extract the individual metric values from the
<code>history_dict</code> and assign them to separate variables for ease
of use. - The <code>loss</code> variable stores the values of the loss
metric recorded during the training epochs. - The
<code>root_mean_squared_error</code> variable stores the values of the
RMSE metric recorded during the training epochs. - The
<code>val_loss</code> variable stores the values of the validation loss
metric recorded during the training epochs. - The
<code>val_root_mean_squared_error</code> variable stores the values of
the validation RMSE metric recorded during the training epochs. Finally,
the <code>epochs</code> variable is assigned to a range of values from 1
to the length of the <code>loss</code> variable plus one. When
visualizing the training history, this range represents the number of
epochs. As a result of capturing and organizing the model's training
history metrics into separate variables, this code enables further
analysis, plotting, or interpretation of the model's performance during
training. In addition to providing insights into the model's convergence
and improvement over time, these metrics also provide information about
its generalization ability.</p>
</div>
<div class="cell code" data-execution_count="19"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:334}"
id="ExABS58lFHrS" data-outputId="8f3d3aaa-f907-47b3-c6fb-f617d6774e25">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">5</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">15</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, loss, label <span class="op">=</span> <span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, val_loss, label <span class="op">=</span> <span class="st">&#39;Validation Loss&#39;</span>)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>ax1.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Training Root Mean Squared Error&quot;</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, val_root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Validation Root Mean Squared Error&quot;</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>ax2.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/65051a56562acd35e58636089da50af98c5947bf.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>This code generates a visualization that displays the training
history of the <code>AAPL_Model</code> in the form of two line plots
side by side. The first line of code creates a figure (<code>fig</code>)
with two subplots (<code>ax1</code> and <code>ax2</code>) arranged
horizontally (side by side) using the <code>plt.subplots()</code>
function from the matplotlib.pyplot library. The following two lines of
code adjust the size of the figure, setting its height to 5 units and
width to 15 units using the <code>set_figheight()</code> and
<code>set_figwidth()</code> Afterwards, the code plots the training
history metrics on the subplots. Ax1 plots the training loss (loss) and
validation loss (val_loss) as functions of epochs (epochs). In this
plot, the x-axis is labeled "Epochs" and the y-axis is labeled "Loss".
It is now possible to distinguish between training loss and validation
loss using a legend.</p>
<p>Similarly, for <code>ax2</code>, the code plots the training root
mean squared error (<code>root_mean_squared_error</code>) and the
validation root mean squared error
(<code>val_root_mean_squared_error</code>) as functions of the number of
epochs (<code>epochs</code>). Accordingly, the x-axis is labeled
"Epochs" and the y-axis is labeled "Root Mean Squared Error". A legend
is added to differentiate between the training RMSE and validation
RMSE.</p>
<p>Finally, the <code>plt.show()</code> function is called to display
the generated plot.</p>
<p>By executing this code, two line plots are generated side by side,
presenting the training history of the <code>AAPL_Model</code> in terms
of loss and RMSE metrics. As a result of this visualization, it is
possible to assess and interpret the training behavior and convergence
of the model over the various training epochs.</p>
</div>
<div class="cell markdown" id="zrM4MV_A1Y26">
<p>Predicting Apple's closing stock price</p>
</div>
<div class="cell code" data-execution_count="20" id="BlBhKm6dEye7">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>AAPL_prediction <span class="op">=</span> AAPL_Model.predict(AAPL_Test_X)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code makes predictions using the <code>AAPL_Model</code> machine
learning model on the testing data (<code>AAPL_Test_X</code>). A trained
model can be predicted using the TensorFlow Keras library's predict()
function. In this specific code, the <code>AAPL_Test_X</code> data is
passed as an argument to the <code>predict()</code> function. When this
code is run, it generates predictions for the input features in
<code>AAPL_Test_X</code>. This variable is used to assign the predicted
values generated by the model to the corresponding input samples in the
testing data. These predictions represent the model's estimated outputs
or target values for the corresponding input samples in the testing
data. Using these predictions, one can evaluate the model's performance
on testing data, compare it with the true target values, or predict new
data that will not be available until later. This code allows the
evaluation and analysis of the model's performance and generalization
ability to unseen data by making predictions based on its trained model
on testing data. In the context of the AAPL dataset, it facilitates
further analysis or decision-making based on the model's
predictions.</p>
</div>
<div class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:351}"
id="zKt-0GuXEFbL" data-outputId="53c40a47-f4cb-4c7a-e64f-7fd7e9f1c2f7">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>plt.plot(AAPL[<span class="st">&#39;Date&#39;</span>][AAPL[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-10-12&#39;</span>], AAPL[<span class="st">&#39;Adj. Close&#39;</span>][AAPL[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-10-12&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Training&#39;</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plt.plot(AAPL[<span class="st">&#39;Date&#39;</span>][AAPL[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-09&#39;</span>], AAPL[<span class="st">&#39;Adj. Close&#39;</span>][AAPL[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-09&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Testing&#39;</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>plt.plot(AAPL[<span class="st">&#39;Date&#39;</span>][AAPL[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-12&#39;</span>], AAPL_prediction.reshape(<span class="op">-</span><span class="dv">1</span>), label <span class="op">=</span> <span class="st">&#39;Predictions&#39;</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Time&#39;</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Closing Price&#39;</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>plt.legend(loc <span class="op">=</span> <span class="st">&#39;best&#39;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="21">
<pre><code>&lt;matplotlib.legend.Legend at 0x7f9684fbce90&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/80044b2fb39cdba91864d169d5b6bcc3ce9e014a.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>To visualize the closing prices of AAPL stock, as well as the
training data, testing data, and predictions made by the model, this
code generates a line plot.</p>
<p>The first line of code sets the figure size of the plot to 20 units
in width and 5 units in height using the
<code>plt.figure(figsize=(20, 5))</code> function from the
matplotlib.pyplot library.</p>
<p>The next three lines of code create the line plots. The first plot
represents the training data, where the x-axis values are the dates
(<code>AAPL['Date'][AAPL['Date'] &lt; '2020-10-12']</code>) and the
y-axis values are the corresponding adjusted closing prices
(<code>AAPL['Adj. The close date is [AAPL['Date'] &lt; '2020-10-12']</code>).
This plot represents the testing data, where the x-axis values are the
dates (<code>AAPL['Date'][AAPL['Date'] &gt;= '2020-10-09']</code>) and
the y-axis values are the corresponding adjusted closing prices
(<code>AAPL['Adj. (AAPL['Date'] &gt;= '2020-10-09')). The third plot represents the predictions made by the model, where the x-axis values are the dates (</code>AAPL['Date'][AAPL['Date']
&gt;=
'2020-10-12']<code>) and the y-axis values are the predicted closing prices (</code>AAPL_prediction.reshape(-1)<code>).  The following lines of code set the x-axis label to "Time" and the y-axis label to "Closing Price" using the</code>plt.xlabel()<code>and</code>plt.ylabel()<code>functions, respectively.  The</code>plt.legend(loc='best')<code>line adds a legend to the plot, which identifies the lines in the The story. The</code>loc='best'`
argument automatically determines the best position for the legend based
on the available space in the plot.</p>
<p>It generates a line plot showing the closing prices of Apple's stock
over time, along with the model predictions and training data. The
visualization helps in understanding how the model performs in relation
to the actual closing prices and provides a visual representation of its
accuracy.</p>
</div>
<div class="cell code" data-execution_count="22"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Rk9tSItpFveZ" data-outputId="2f2bb456-a8ca-4265-84cc-6ae3d0e88a18">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> math.sqrt(mean_squared_error(AAPL_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>), AAPL_prediction))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> np.mean(np.<span class="bu">abs</span>(AAPL_prediction <span class="op">-</span> AAPL_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>))<span class="op">/</span>np.<span class="bu">abs</span>(AAPL_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>)))</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE: </span><span class="sc">{</span>rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MAPE: </span><span class="sc">{</span>mape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE: 4.822911467470171
MAPE: 0.030390689646776783
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>To assess the model's performance on AAPL testing data, this code
computes and prints two evaluation metrics, RMSE (Root Mean Squared
Error) and MAPE (Mean Absolute Percentage Error).</p>
<p>The first line of code calculates the RMSE using the
<code>mean_squared_error()</code> function from the sklearn.metrics
module. The mean squared error is calculated by comparing the predicted
values with the true values (AAPL_Test_Y.reshape(-1, 5)). The
<code>math.sqrt()</code> function is then used to take the square root
of the mean squared error, giving us the RMSE value. Numpy's mean and
average functions are then used to calculate the MAPE. It calculates the
absolute percentage error for each prediction by taking the absolute
difference between the predicted values and the true values, dividing it
by the absolute true values, and then averaging these values using
<code>np.mean()</code>.</p>
<p>The <code>print()</code> function is used to display the calculated
values of RMSE and MAPE. The <code>f-string</code> notation
(<code>f'RMSE: {rmse}'</code> and <code>f'MAPE: {mape}'</code>) is used
to format the output and insert the calculated metric values into the
printed string.</p>
<p>By executing this code, the RMSE and MAPE values are calculated and
displayed, providing quantitative measures of the model's accuracy and
performance on the AAPL testing data. RMSE is the average difference
between predicted and true values, while MAPE is the average percentage
error. Regression models are commonly evaluated using these metrics to
determine their quality and reliability.</p>
</div>
<div class="cell markdown" id="ypf8ZYJOLDBM">
<p>Elon Musk</p>
</div>
<div class="cell code" data-execution_count="23"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:195}"
id="QJq_CWY6TPHd" data-outputId="471a8905-1005-45bd-aa3b-f24cb7c86e8a">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>TSLA.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="23">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj. Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2015-01-02</td>
      <td>44.57</td>
      <td>44.65</td>
      <td>42.65</td>
      <td>43.86</td>
      <td>43.86</td>
      <td>23822000.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2015-01-05</td>
      <td>42.91</td>
      <td>43.30</td>
      <td>41.43</td>
      <td>42.02</td>
      <td>42.02</td>
      <td>26842500.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2015-01-06</td>
      <td>42.01</td>
      <td>42.84</td>
      <td>40.84</td>
      <td>42.26</td>
      <td>42.26</td>
      <td>31309500.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2015-01-07</td>
      <td>42.67</td>
      <td>42.96</td>
      <td>41.96</td>
      <td>42.19</td>
      <td>42.19</td>
      <td>14842000.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2015-01-08</td>
      <td>42.56</td>
      <td>42.76</td>
      <td>42.00</td>
      <td>42.12</td>
      <td>42.12</td>
      <td>17212500.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>The first few rows of the TSLA DataFrame are displayed in this code.
The <code>.head()</code> function is a method provided by the pandas
library that allows us to inspect the top portion of a DataFrame. Upon
execution, this code displays the first few rows of the TSLA DataFrame.
By default, it displays the first five rows, but this can be customized
by passing a specific number as an argument to the <code>.head()</code>
function. It is used to quickly get an overview of TSLA DataFrame data.
By inspecting the top rows, we can examine the column names and the
values in the dataset, which helps in understanding the structure and
content of the data. We can use this information to explore and clean
the data. It provides a glimpse into the TSLA DataFrame's format and
content and allows us to verify if the data has been loaded
correctly.</p>
</div>
<div class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pyL1B3uMTUNv" data-outputId="ec027b1a-8917-4d44-faaa-e3d082a7792a">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>TSLA.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1549 entries, 0 to 1548
Data columns (total 7 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   Date        1549 non-null   object 
 1   Open        1549 non-null   float64
 2   High        1549 non-null   float64
 3   Low         1549 non-null   float64
 4   Close       1549 non-null   float64
 5   Adj. Close  1549 non-null   float64
 6   Volume      1549 non-null   float64
dtypes: float64(6), object(1)
memory usage: 84.8+ KB
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>TSLA DataFrame summary information is provided by this code. The
<code>.info()</code> function is provided by the pandas library that
displays a concise summary of the DataFrame's structure and contents.
This code gives information about TSLA DataFrames, including column
names, the number of non-null values in each column, and its data type,
when executed. Furthermore, it provides an overall summary that includes
the total number of entries (rows) in the DataFrame. This function
provides an overview of the dataset's structure and characteristics. It
helps in understanding the data types of each column, identifying
missing or null values, and estimating the memory usage of the
DataFrame. Using this information is useful for data exploration, data
cleaning, and initial data analysis. The data will be evaluated for
quality and completeness, converted into a data type or handled with
missing values, and we can make informed decisions about how to proceed
with data processing or analysis.</p>
<p>By using <code>.info()</code>, we gain insights into the basic
properties of the TSLA DataFrame, enabling us to proceed with subsequent
data manipulations and analysis with a clearer understanding of the
data's composition.</p>
</div>
<div class="cell code" data-execution_count="25" id="acJ0D4D8TbuT">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change Dtype of Date column</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>TSLA[<span class="st">&quot;Date&quot;</span>] <span class="op">=</span> pd.to_datetime(TSLA[<span class="st">&quot;Date&quot;</span>])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code changes the data type of the "Date" column in the TSLA
DataFrame to the datetime format using the <code>pd.to_datetime()</code>
function provided by the pandas library.</p>
<p>As a result of executing this code, the TSLA DataFrame's "Date"
column is converted from its original data type (presumably a string or
another format) to datetime format. The datetime format is a
standardized representation of dates and times that allows for easier
manipulation and analysis of temporal data. To convert the "Date" column
to this format, use the function pd.to_datetime(). By doing so, the
"Date" column will be interpreted as dates instead of mere numbers or
text. It is possible to filter or sort the DataFrame based on dates,
extract specific components (year, month, day), calculate time
differences, and perform time-based analysis by changing the data type
of the "Date" column to datetime. Basically, this code ensures that the
"Date" column in the TSLA DataFrame is recognized as datetime data,
enabling Datasets with seamless handling and utilization of temporal
information.</p>
</div>
<div class="cell markdown" id="fdCQQVG36NtH">
<p>Split the Data into Training and Test set. Training Period:
2015-01-02 - 2020-09-30 and Testing Period: 2020-10-01 - 2021-12-26</p>
</div>
<div class="cell code" data-execution_count="26" id="MJ4YxPbLTogR">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>TSLA_Date <span class="op">=</span> <span class="st">&#39;2020-10-01&#39;</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>TSLA_Train_X, TSLA_Train_Y, TSLA_Test_X, TSLA_Test_Y <span class="op">=</span> Dataset(TSLA, TSLA_Date)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code prepares the TSLA dataset for training and testing by
splitting it into four sets of data: TSLA_Train_X, TSLA_Train_Y,
TSLA_Test_X, and TSLA_Test_Y. It starts off by assigning the value
2020-10-01 to the variable <code>TSLA_Date</code>. This represents the
date that will be used as a reference point for splitting the data. The
second line calls the Dataset function with TSLA dataset and TSLA_Date.
The <code>Dataset</code> function is responsible for performing the
actual splitting of the data. The <code>Dataset</code> function takes
the TSLA dataset and the <code>TSLA_Date</code> as inputs and returns
four sets of data: <code>TSLA_Train_X</code>, <code>TSLA_Train_Y</code>,
<code>TSLA_Test_X</code>, and <code>TSLA_Test_Y</code>.
<code>TSLA_Train_X</code> and <code>TSLA_Train_Y</code> represent the
training data, where <code>TSLA_Train_X</code> contains the input
features and <code>TSLA_Train_Y</code> contains the corresponding output
labels or target values. <code>TSLA_Test_X</code> and
<code>TSLA_Test_Y</code> represent the testing data, where
<code>TSLA_Test_X</code> contains the input features for testing and
<code>TSLA_Test_Y</code> contains the corresponding expected output
labels or target values for evaluation. By calling the
<code>Dataset</code> function and assigning the returned values to
specific variables, this code organizes the TSLA dataset into separate
training and testing sets, which can be further used for training a
machine learning model, evaluating its performance, or conducting any
other analysis related to the dataset.</p>
</div>
<div class="cell markdown" id="aYKWpHMa17Kh">
<p>Fitting of the model</p>
</div>
<div class="cell code" data-execution_count="27" id="SH2GuSX6T2Cm">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>TSLA_Model <span class="op">=</span> Model()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>The code creates an instance of a machine learning model specifically
designed for the TSLA dataset. This code initializes a variable named
<code>TSLA_Model</code> and assigns it the value returned by the
<code>Model()</code> function. The <code>Model()</code> function is
responsible for constructing and configuring the specific machine
learning model architecture.</p>
<p>By calling the <code>Model()</code> function, the code instantiates
the <code>TSLA_Model</code> object, which represents the machine
learning model tailored for the TSLA dataset.</p>
<p>The <code>TSLA_Model</code> object encapsulates the architecture,
parameters, and functionality defined within the <code>Model()</code>
function. In addition to training the model on TSLA training data, it
can also be used to make predictions, evaluate its performance, or
perform other machine learning operations. A machine learning model that
is specific to the TSLA dataset is created in this code, which allows
the model to be used for analysis, prediction, and other tasks related
to TSLA stock data.</p>
</div>
<div class="cell code" data-execution_count="28" id="w-nr1vkYT_JJ">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>TSLA_Model.<span class="bu">compile</span>(optimizer <span class="op">=</span> tf.keras.optimizers.Adam(), loss <span class="op">=</span> <span class="st">&#39;mse&#39;</span>, metrics <span class="op">=</span> tf.keras.metrics.RootMeanSquaredError())</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code configures the compilation settings for the
<code>TSLA_Model</code> machine learning model. This code uses the
TensorFlow Keras library's compile() function to specify various
training settings. It takes several arguments to define the optimizer,
loss function, and metrics to be used during the training process. For
example, the optimizer argument is set to Adam(), which initializes the
Adam optimizer. The optimizer determines how the model's weights are
updated during training, and Adam is a popular optimization algorithm
widely used in deep learning. MSE stands for mean square error. This
indicates that the mean squared error is used as the loss function to
measure the discrepancy between the predicted outputs and the true
outputs during training.</p>
<p>The <code>metrics</code> argument is set to
<code>tf.keras.metrics.RootMeanSquaredError()</code>, which initializes
the root mean squared error (RMSE) as the evaluation metric. The RMSE
metric provides a measure of how well the model performs in terms of the
average difference between the predicted and true outputs.</p>
<p>By configuring these settings through the <code>compile()</code>
function, the code prepares the <code>TSLA_Model</code> for the training
process, specifying the optimization algorithm, loss function, and
evaluation metric to be used. In order to train the model effectively
and assess its performance accurately, these settings are crucial.</p>
</div>
<div class="cell code" id="GcfkNJk2ULD0">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>TSLA_hist <span class="op">=</span> TSLA_Model.fit(TSLA_Train_X, TSLA_Train_Y, epochs <span class="op">=</span> <span class="dv">200</span>, validation_data <span class="op">=</span> (TSLA_Test_X, TSLA_Test_Y), callbacks<span class="op">=</span>[callback])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code trains the <code>TSLA_Model</code> machine learning model
using the training data (<code>TSLA_Train_X</code> and
<code>TSLA_Train_Y</code>) and evaluates its performance on the testing
data (<code>TSLA_Test_X</code> and <code>TSLA_Test_Y</code>).</p>
<p>The <code>fit()</code> method is a function provided by the
TensorFlow Keras library that performs the training process for a
machine learning model. It takes several arguments to specify the
training data, the number of training epochs, the validation data for
evaluation, and any additional callbacks to be utilized during
training.</p>
<p>In this specific code, <code>TSLA_Train_X</code> and
<code>TSLA_Train_Y</code> are passed as the training data, representing
the input features and the corresponding output labels,
respectively.</p>
<p>The <code>epochs</code> argument is set to 200, indicating the number
of times the training data will be iterated over during the training
process. Each epoch represents a complete pass through the entire
training dataset. For training purposes, the validation data is set to
(TSLA_Test_X, TSLA_Test_Y). This allows for monitoring the model's
performance on unseen data and helps in assessing its generalization
ability. It is set to a callback object (such as a learning rate
scheduler). Callbacks provide additional functionalities during
training, such as modifying the learning rate or saving the model's
checkpoints. This code trains the TSLA_Model with the specified training
data. The model's performance is evaluated on the testing data after
each epoch, and the training history is stored in the
<code>TSLA_hist</code> object, which can be used to analyze the model's
training progress and performance metrics.</p>
<p>Overall, this code initiates and manages the training process for the
<code>TSLA_Model</code>, allowing it to learn from the training data and
improve its performance over the specified number of epochs.</p>
</div>
<div class="cell code" data-execution_count="30" id="ZXWgxxkkUXt-">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>history_dict <span class="op">=</span> TSLA_hist.history</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history_dict[<span class="st">&quot;loss&quot;</span>]</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;root_mean_squared_error&quot;</span>]</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history_dict[<span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>val_root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;val_root_mean_squared_error&quot;</span>]</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code extracts the training history of the
<code>TSLA_Model</code> after the training process is completed. It
captures the values of different metrics recorded during training and
organizes them into separate variables for further analysis and
visualization. The first line of code assigns the history_dict variable
to the TSLA_Model. The <code>history</code> attribute of the
<code>TSLA_hist</code> object contains various recorded metrics such as
loss, root mean squared error (RMSE), validation loss, and validation
RMSE. The subsequent lines of code extract the individual metric values
from the <code>history_dict</code> and assign them to separate variables
for ease of use. - The <code>loss</code> variable stores the values of
the loss metric recorded during the training epochs. - The
<code>root_mean_squared_error</code> variable stores the values of the
RMSE metric recorded during the training epochs. - The
<code>val_loss</code> variable stores the values of the validation loss
metric recorded during the training epochs. - The
<code>val_root_mean_squared_error</code> variable stores the values of
the validation RMSE metric recorded during the training epochs. Finally,
the <code>epochs</code> variable is assigned to a range of values from 1
to the length of the <code>loss</code> variable plus one. When
visualizing the training history, this range will be used as the x-axis
value.</p>
<p>By capturing and organizing the training history metrics in separate
variables, this code enables further analysis, plotting, or
interpretation of the model's performance throughout the training
process. A model's convergence, improvement, and generalization ability
over epochs can be determined by these metrics.</p>
</div>
<div class="cell code" data-execution_count="31"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:334}"
id="fkrETLmdUy88" data-outputId="0f24d23b-a061-495e-ddcb-2eea048752ce">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">5</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">15</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, loss, label <span class="op">=</span> <span class="st">&quot;Training Loss&quot;</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, val_loss, label <span class="op">=</span> <span class="st">&quot;Validation Loss&quot;</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>ax1.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Training Root Mean Squared Error&quot;</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, val_root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Validation Root Mean Squared Error&quot;</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>ax2.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/1c51e9ab0ea0348b78cd9fd0f87f2d7cd4f47485.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>This code generates a figure with two subplots and plots the training
history metrics of the <code>TSLA_Model</code> on each subplot using the
matplotlib.pyplot library. It begins by defining two subplots (ax1 and
ax2) and arranging them side by side. The number of rows and columns in
the subplot grid is specified as 1 row and 2 columns, respectively. The
following two lines of code adjust the figure's size. The
<code>set_figheight()</code> function sets the height of the figure to 5
units, and the <code>set_figwidth()</code> function sets the width of
the figure to 15 units. The training history metrics are then plotted on
each subplot. In the case of <code>ax1</code>, two line plots are
created. There are two plots: one represents the training loss (loss) as
a function of the number of epochs (epochs), the other represents the
validation loss (val_loss). The plots are labeled accordingly, with the
x-axis labeled as "Epochs" and the y-axis labeled as "Loss". A legend is
added to distinguish between the training loss and validation loss. For
<code>ax2</code>, two line plots are created. Plots 1, 2, and 3
represent the training root mean square error (RMSE) as a function of
epochs, and plots 4, 5, and 6 represent the validation RMSE. "Epochs" is
the x-axis, and "Loss" is the y-axis. A legend is added to differentiate
between the training RMSE and validation RMSE.</p>
<p>Finally, the <code>plt.show()</code> function is called to display
the generated plot.</p>
<p>By executing this code, a figure with two subplots is generated, each
containing line plots of the training history metrics of the
<code>TSLA_Model</code>. In this visualization, the training progress
and performance of the model are clearly depicted, allowing easy
comparison and interpretation of the loss and RMSE metrics over
time.</p>
</div>
<div class="cell markdown" id="kz5vH7re1Unf">
<p>Predicting Tesla's closing stock price</p>
</div>
<div class="cell code" data-execution_count="32" id="LvaeZqRJUe1C">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>TSLA_prediction <span class="op">=</span> TSLA_Model.predict(TSLA_Test_X)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code uses the trained <code>TSLA_Model</code> to make
predictions on the testing data (<code>TSLA_Test_X</code>). TensorFlow
Keras provides the predict function that allows for making predictions,
based on a trained model. In this specific code, the
<code>TSLA_Test_X</code> data is passed as an argument to the
<code>predict()</code> function. It is this code that generates
predictions for the input features provided in the
<code>TSLA_Test_X</code>. These predictions represent the model's
estimated outputs or target values for the corresponding input samples
in the testing data. These values are assigned to the TSLA_prediction
variable. These predictions can be used for various purposes, such as
evaluating the model's performance on the testing data, comparing them
with the true target values (<code>TSLA_Test_Y</code>), or making
predictions for new, unseen data.</p>
<p>This code allows the model to perform and analyze its performance and
ability to generalize to unseen data by evaluating and analyzing the
model's performance on the testing data. Based on the TSLA dataset, it
facilitates further analysis or decision-making.</p>
</div>
<div class="cell code" data-execution_count="33"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:351}"
id="2wuKdS85Ut1t" data-outputId="abfe5cfe-2101-4df4-e580-8686fc36849d">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>plt.plot(TSLA[<span class="st">&#39;Date&#39;</span>][TSLA[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-10-12&#39;</span>], TSLA[<span class="st">&#39;Adj. Close&#39;</span>][TSLA[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-10-12&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Training&#39;</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>plt.plot(TSLA[<span class="st">&#39;Date&#39;</span>][TSLA[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-09&#39;</span>], TSLA[<span class="st">&#39;Adj. Close&#39;</span>][TSLA[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-09&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Testing&#39;</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>plt.plot(TSLA[<span class="st">&#39;Date&#39;</span>][TSLA[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-12&#39;</span>], TSLA_prediction.reshape(<span class="op">-</span><span class="dv">1</span>), label <span class="op">=</span> <span class="st">&#39;Predictions&#39;</span>)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Time&#39;</span>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Closing Price&#39;</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>plt.legend(loc <span class="op">=</span> <span class="st">&#39;best&#39;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="33">
<pre><code>&lt;matplotlib.legend.Legend at 0x7f968415de50&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/a30c598eb46e8e556797fb4600663f27619796ee.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>The code creates a plot that visualizes historical stock price data
for TSLA, training data, testing data, and model predictions. The first
line of code sets the figure size to (10, 5), indicating the width and
height of the plot in inches.</p>
<p>The subsequent lines of code create the line plots. Three separate
lines are plotted on the same figure: The first line plot shows the
historical stock prices of TSLA during the training period. The TSLA
DataFrame's 'Date' column is used to filter corresponding dates before
'2020-10-12'. 'Adj.' The closing prices are plotted using the 'Close'
column. This line is labeled as 'Training'. The second line represents
the historical stock prices of TSLA during the testing period. TSLA
DataFrame's 'Date' column is used to filter dates on or after
'2020-10-09'. 'Adj.' The closing prices are plotted using the 'Close'
column. This line is labeled as 'Testing'. The third line represents the
model's predictions for the testing period. TSLA DataFrame's 'Date'
column is used to filter the corresponding dates on or after
'2020-10-12'. TSLA_prediction, which contains predicted closing prices,
is plotted against these dates. This line is labeled as
'Predictions'.</p>
<p>Additional code lines set the x-axis label to 'Time', the y-axis
label to 'Closing Price', and add a legend to identify the different
lines on the plot.</p>
<p>The model's predictions along with the historical stock prices of
Tesla are displayed in this plot generated by executing this code. The
visualization shows the actual stock prices, the model's performance in
predicting prices, and the training and testing periods. By comparing
the observed prices and the model's predictions, we are able to assess
the model's accuracy and effectiveness in capturing the underlying
patterns in the TSLA stock data.</p>
</div>
<div class="cell code" data-execution_count="34"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="GtI6XOGNUmqG" data-outputId="e9b5d415-886a-42d9-c71f-8deb636a399b">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> math.sqrt(mean_squared_error(TSLA_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>), TSLA_prediction))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> np.mean(np.<span class="bu">abs</span>(TSLA_prediction <span class="op">-</span> TSLA_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>))<span class="op">/</span>np.<span class="bu">abs</span>(TSLA_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>)))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE: </span><span class="sc">{</span>rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MAPE: </span><span class="sc">{</span>mape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE: 66.40686299614501
MAPE: 0.07223948908878701
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>A model's performance compared to true values can be evaluated by
calculating and printing the root mean squared error (RMSE) and the mean
absolute percent error (MAPE).</p>
<p>The first line of code calculates the RMSE between the true target
values (<code>TSLA_Test_Y</code>) and the model's predictions
(<code>TSLA_prediction</code>). To calculate the mean squared error
between two sets of values, we use the scikit-learn function
mean_squared_error(). The <code>math.sqrt()</code> function is then
applied to take the square root of the mean squared error, resulting in
the RMSE. The second line calculates the MAPE between the true target
values and the model predictions. The <code>np.abs()</code> function
computes the absolute difference between the predicted value and the
true value, and the result is divided by the true value. These values
are then averaged using the <code>np.mean()</code> function to obtain
the MAPE. The third line prints the calculated RMSE. The value of
<code>rmse</code> is displayed in place of <code>{rmse}</code>. Line
four prints the calculated MAPE. The value of <code>mape</code> is
displayed in place of <code>{mape}</code>. The RMSE and MAPE metrics are
computed and displayed, providing quantitative measures of the model's
accuracy and percentage error. In addition to capturing the patterns and
trends in the TSLA stock data, these metrics serve as indicators of how
well the model aligns with the true values.</p>
</div>
<div class="cell markdown" id="2JhHyPLLYnUY">
<p>Search engine</p>
</div>
<div class="cell code" data-execution_count="35"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:195}"
id="Ss34732uYmXB" data-outputId="13da1f56-696c-4d35-f6c6-8e9be62d0666">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>GOOG.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="35">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj. Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2015-01-02</td>
      <td>527.56</td>
      <td>529.82</td>
      <td>522.67</td>
      <td>523.37</td>
      <td>523.37</td>
      <td>1447563.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2015-01-05</td>
      <td>521.83</td>
      <td>522.89</td>
      <td>511.66</td>
      <td>512.46</td>
      <td>512.46</td>
      <td>2059840.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2015-01-06</td>
      <td>513.59</td>
      <td>514.76</td>
      <td>499.68</td>
      <td>500.59</td>
      <td>500.59</td>
      <td>2899940.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2015-01-07</td>
      <td>505.61</td>
      <td>505.86</td>
      <td>498.28</td>
      <td>499.73</td>
      <td>499.73</td>
      <td>2065054.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2015-01-08</td>
      <td>496.63</td>
      <td>502.10</td>
      <td>489.66</td>
      <td>501.30</td>
      <td>501.30</td>
      <td>3353582.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>This code retrieves the first few rows of data from the GOOG
DataFrame. Pandas' head() function allows viewing the top rows of a
DataFrame. By calling <code>GOOG.head()</code>, the code retrieves the
first few rows of the GOOG DataFrame, displaying them in the output.
This is used to quickly see the GOOG DataFrame's structure and content.
This summary provides a concise summary of the data, including column
names and initial rows, which can be useful for understanding the data
and performing initial explorations. With this code, you will see the
first few rows of the GOOG DataFrame, giving you an overview of the data
and allowing you to get a feel for its format and values.</p>
</div>
<div class="cell code" data-execution_count="36"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="n5JxMBTjZ_2Q" data-outputId="7f4f54f7-1aca-42d8-e58b-fe99dd399a64">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>GOOG.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1549 entries, 0 to 1548
Data columns (total 7 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   Date        1549 non-null   object 
 1   Open        1549 non-null   float64
 2   High        1549 non-null   float64
 3   Low         1549 non-null   float64
 4   Close       1549 non-null   float64
 5   Adj. Close  1549 non-null   float64
 6   Volume      1549 non-null   float64
dtypes: float64(6), object(1)
memory usage: 84.8+ KB
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>This code provides detailed information about the structure and
content of the GOOG DataFrame. An overview of the dataframe's metadata
is provided by the info() function in the pandas library. By calling
<code>GOOG.info()</code>, the code prints out several pieces of
information about the GOOG DataFrame. These include the number of
columns and rows, the type of each column, and the memory usage. It also
provides information about any missing values in the DataFrame and the
count of non-null values for each column. This information gives a
better understanding of the GOOG DataFrame. For data cleaning,
preprocessing, and further analysis, it can be crucial to identify data
types, missing values, and memory usage. By executing this code, the
output will provide a detailed overview of the GOOG DataFrame, providing
information on its size, column type, memory usage, and missing values.
By utilizing this information, data exploration and manipulation tasks
can be performed effectively, assisting in understanding and utilizing
the dataset.</p>
</div>
<div class="cell code" data-execution_count="37" id="SB2BNkTKaGnx">
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change Dtype of Date column</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>GOOG[<span class="st">&quot;Date&quot;</span>] <span class="op">=</span> pd.to_datetime(GOOG[<span class="st">&quot;Date&quot;</span>])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code converts the data type of the "Date" column in the GOOG
DataFrame to a datetime format. The first line accesses the "Date"
column using "GOOG["Date"]". It then assigns the result of the
conversion to the same column, overwriting the existing data. This
function converts a column to a datetime format using the pandas
library. It parses the values in the column and converts them into
datetime objects. When executed, the "Date" column in the GOOG DataFrame
becomes a datetime object. With this conversion, dates can be handled
and manipulated more efficiently, making various time-based analyses and
operations possible.</p>
</div>
<div class="cell markdown" id="ZPLEQ3pv6h2S">
<p>Split the Data into Training and Test set. The Training Period:
2015-01-02 - 2020-10-30 The Testing Period: 2020-11-02 - 2021-02-26</p>
</div>
<div class="cell code" data-execution_count="38" id="CATiVyQ4aZ93">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>GOOG_Date <span class="op">=</span> <span class="st">&#39;2020-11-01&#39;</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>GOOG_Train_X, GOOG_Train_Y, GOOG_Test_X, GOOG_Test_Y <span class="op">=</span> Dataset(GOOG, GOOG_Date)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code prepares the training and testing datasets for the GOOG
stock data based on a specified date. It assigns the value '2020-11-01'
to the variable GOOG_Date. This represents the date that will be used to
split the data into training and testing sets. It is called with two
arguments: <code>GOOG</code> and <code>GOOG_Date</code>. The
<code>Dataset()</code> function is a custom function that takes a
dataset and a specific date as input. When this code is run, the GOOG
dataset and the specified date are passed as arguments. The function
processes the data and splits it into four sets:
<code>GOOG_Train_X</code>, <code>GOOG_Train_Y</code>,
<code>GOOG_Test_X</code>, and <code>GOOG_Test_Y</code>. -
<code>GOOG_Train_X</code> represents the input features of the training
dataset, which will be used to train the model. -
<code>GOOG_Train_Y</code> represents the corresponding output labels or
target values of the training dataset. - <code>GOOG_Test_X</code>
represents the input features of the testing dataset, which will be used
to evaluate the trained model. - <code>GOOG_Test_Y</code> represents the
This code creates separate training and testing datasets based on the
specified date. It splits the GOOG stock data based on the specified
date. As a result, the model can be trained on historical data and
assessed on unseen data from a specific point in time.</p>
</div>
<section id="fitting-of-the-model" class="cell markdown"
id="toxFZOh914XG">
<h3>Fitting of the model</h3>
</section>
<div class="cell code" data-execution_count="39" id="RV2GNSl6aaBf">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>GOOG_Model <span class="op">=</span> Model()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code creates an instance of a machine learning model called
<code>GOOG_Model</code> specifically designed for the GOOG stock data.
This function returns a predefined machine learning model architecture.
The architecture of the model is specified within the
<code>Model()</code> function and typically includes various layers,
such as LSTM (Long Short-Term Memory) layers and dense layers, to
capture patterns and relationships in the data.</p>
<p>By executing this code, the <code>GOOG_Model</code> object is
instantiated, representing the machine learning model that will be used
to learn patterns and make predictions on the GOOG stock data. The model
instance can be trained, evaluated, and used to make future predictions,
based on the parameters and architecture specified within the
<code>Model()</code> function.</p>
</div>
<div class="cell code" data-execution_count="40" id="PPjOZW8AaaFD">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>GOOG_Model.<span class="bu">compile</span>(optimizer <span class="op">=</span> tf.keras.optimizers.Adam(), loss <span class="op">=</span> <span class="st">&#39;mse&#39;</span>, metrics <span class="op">=</span> tf.keras.metrics.RootMeanSquaredError())</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code configures the compilation of the <code>GOOG_Model</code>
by specifying the optimizer, loss function, and evaluation metric.
TensorFlow Keras provides the compile() function. In this code, it is
called on the <code>GOOG_Model</code> object. Its first argument,
optimizer, sets the optimizer that adjusts the model's parameters during
training. In this case, the Adam optimizer is chosen, which is a popular
optimization algorithm commonly used in deep learning models. The second
argument, loss, specifies a loss function that measures the discrepancy
between the predicted and true values. It uses the mean squared error
(MSE) loss function, which calculates the average squared difference
between the predicted and true values. It uses metrics to evaluate the
model's performance. The root mean squared error (RMSE) is used as the
metric in this code. RMSE provides a measure of the average prediction
error, similar to the MSE but in the original scale of the data. It
compiles the Google model using the specified optimizer, loss function,
and evaluation metric. In this configuration, the model is prepared for
training by specifying how its parameters should be optimized, the loss
calculated, and the performance tracked.</p>
</div>
<div class="cell code" id="Fh9miHDgaaIk">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>GOOG_hist <span class="op">=</span> GOOG_Model.fit(GOOG_Train_X, GOOG_Train_Y, epochs <span class="op">=</span> <span class="dv">1000</span>, validation_data <span class="op">=</span> (GOOG_Test_X, GOOG_Test_Y), callbacks <span class="op">=</span> [callback])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code trains the <code>GOOG_Model</code> using the training
datasets <code>GOOG_Train_X</code> and <code>GOOG_Train_Y</code>, and
validates its performance using the testing datasets
<code>GOOG_Test_X</code> and <code>GOOG_Test_Y</code>.</p>
<p>The <code>fit()</code> function is a method provided by the
TensorFlow Keras library. It is called on the <code>GOOG_Model</code>
object to train the model. GOOG_Train_X and GOOG_Train_Y are the input
features and target values for the training dataset, respectively. These
datasets are used to train the model by iteratively adjusting its
parameters based on the provided inputs and desired outputs. When
training the model, the epochs parameter specifies how many times the
model will iterate over the entire training dataset. In this code, the
model is trained for 1000 epochs, meaning it will go through the
training data 1000 times. As indicated in the validation_data parameter,
the validation dataset is (GOOG_Test_X, GOOG_Test_Y). For monitoring the
model's progress and to identify potential overfitting or underfitting,
the model's loss and metrics will be computed after each epoch on this
validation dataset.</p>
<p>The <code>callbacks</code> parameter is set to
<code>[callback]</code>, which allows for the inclusion of callback
functions during the training process. At specific points during
training, callbacks can perform additional actions. In this code, the
<code>callback</code> function (previously defined) is included as a
callback, potentially for adjusting the learning rate during training.
Upon execution, the <code>GOOG_Model</code> is trained on the training
dataset for the specified number of epochs. In order to minimize the
loss and improve the model's performance, the parameters are updated
iteratively. Validation datasets are used to evaluate the model's
performance and provide feedback on its generalization capability. This
object records the history of the training process, including the loss
and metrics values at each epoch, which can be analyzed and
visualized.</p>
</div>
<div class="cell code" data-execution_count="42" id="vp7tR-PBaaL8">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>history_dict <span class="op">=</span> GOOG_hist.history</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history_dict[<span class="st">&quot;loss&quot;</span>]</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;root_mean_squared_error&quot;</span>]</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history_dict[<span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>val_root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;val_root_mean_squared_error&quot;</span>]</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code extracts information from the training history of the
<code>GOOG_Model</code> and assigns it to several variables for further
analysis. It begins by accessing the <code>history</code> attribute of
the <code>GOOG_hist</code> object. The <code>history</code> attribute
contains a dictionary that stores the training history of the model,
including the loss and metrics values at each epoch. Each subsequent
line of code retrieves specific values from the history_dict dictionary.
These values include the training loss (<code>loss</code>), training
root mean squared error (<code>root_mean_squared_error</code>),
validation loss (<code>val_loss</code>), and validation root mean
squared error (<code>val_root_mean_squared_error</code>).</p>
<p>The last line of code creates a range of numbers representing the
epochs, starting from 1 and ending at the length of the
<code>loss</code> list plus 1. This range is assigned to the variable
<code>epochs</code> and can be used as the x-axis values for plotting
the training history. During execution, the relevant data from the
training history of the Google Model is extracted and stored. By
plotting the training and validation metrics over the epochs or
comparing the performances of different models, these variables can be
used for further analysis.</p>
</div>
<div class="cell code" data-execution_count="43"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:345}"
id="DcU99odHbA-f" data-outputId="0e3d7e96-3502-4792-c0e3-3240f063c30a">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">5</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">15</span>)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, loss, label <span class="op">=</span> <span class="st">&quot;Training Loss&quot;</span>)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, val_loss, label <span class="op">=</span> <span class="st">&quot;Validation Loss&quot;</span>)</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>ax1.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Training Root Mean Squared Error&quot;</span>)</span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, val_root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Validation Root Mean Squared Error&quot;</span>)</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>ax2.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/fa9e37db500ff2b1fcd46fea9ef39d8cf6065c19.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>This code creates a figure with two subplots and plots the training
and validation loss, as well as the training and validation root mean
squared error (RMSE) values over the epochs. In the first line, two
subplots are created. The <code>fig</code> variable represents the
overall figure, while <code>ax1</code> and <code>ax2</code> represent
the two subplots within the figure. #Set the height and width of the
figure with the methods set_figheight() and set_figwidth(). These lines
adjust the size of the figure to ensure proper visualization. Following
that are the lines of code that plot the training and validation losses
(<code>ax1</code>). In this example, the plot() function is called on
<code>ax1</code> with <code>epochs</code> as the x-axis values and
<code>loss</code> and <code>val_loss</code> as the y-axis values. The
<code>label</code> argument specifies the labels for each line. The
<code>set()</code> method is then called on <code>ax1</code> to set the
x-axis and y-axis labels. Next, the training and validation root mean
squared errors (RMSE) are plotted. As with the previous lines, the
plot() function is called with <code>epochs</code> as the x-axis values
and <code>root_mean_squared_error</code> and
<code>val_root_mean_squared_error</code> as the y-axis values. The
<code>set()</code> method is used to set the x-axis and y-axis
labels.</p>
<p>The <code>legend()</code> method is called on both subplots to
display a legend indicating the labels of the plotted lines.</p>
<p>Finally, the <code>plt.show()</code> function is called to display
the figure with the plotted subplots.</p>
<p>By executing this code, two subplots are created within a figure, and
the training and validation loss, as well as the training and validation
RMSE values, are plotted over the epochs. A comparison of the model's
performance and convergence of the loss and RMSE values during training
can be made using this visualization.</p>
</div>
<div class="cell markdown" id="YKZETIgK1MgM">
<p>Predicting Google's closing stock price</p>
</div>
<div class="cell code" data-execution_count="44" id="W5on4_hjbFb1">
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>GOOG_prediction <span class="op">=</span> GOOG_Model.predict(GOOG_Test_X)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code uses the trained <code>GOOG_Model</code> to make
predictions on the testing dataset <code>GOOG_Test_X</code>.</p>
<p>The <code>predict()</code> method is called on the
<code>GOOG_Model</code> object, and the input features
<code>GOOG_Test_X</code> are provided as the argument. This code
generates predictions for the testing data using the trained model. When
executed, the <code>GOOG_Model</code> predicts the target values for the
input features in <code>GOOG_Test_X</code>. Predictions are stored in a
variable called Google_prediction, which can be used for further
analysis, evaluation, and visualization. Based on the patterns and
relationships learned during training, these predictions represent the
model's estimation of the target values.</p>
</div>
<div class="cell code" data-execution_count="45"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:351}"
id="jqwt0ivCbBdD" data-outputId="78429ed1-e1fd-4837-c05e-1959aeecc5d6">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>plt.plot(GOOG[<span class="st">&#39;Date&#39;</span>][GOOG[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-11-07&#39;</span>], GOOG[<span class="st">&#39;Adj. Close&#39;</span>][GOOG[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-11-07&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Training&#39;</span>)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>plt.plot(GOOG[<span class="st">&#39;Date&#39;</span>][GOOG[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-11-07&#39;</span>], GOOG[<span class="st">&#39;Adj. Close&#39;</span>][GOOG[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-11-07&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Testing&#39;</span>)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>plt.plot(GOOG[<span class="st">&#39;Date&#39;</span>][GOOG[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-11-07&#39;</span>], GOOG_prediction.reshape(<span class="op">-</span><span class="dv">1</span>), label <span class="op">=</span> <span class="st">&#39;Predictions&#39;</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Time&#39;</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Closing Price&#39;</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>plt.legend(loc <span class="op">=</span> <span class="st">&#39;best&#39;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="45">
<pre><code>&lt;matplotlib.legend.Legend at 0x7f96850a5e50&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/026a0b01abf8aa660575fc5de4749501c65d4e81.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>To visualize the actual closing prices of GOOG, along with the
predicted closing prices and the separation between training and testing
periods, this code generates a plot. In the first line of code, we
specify the figure's size using
<code>plt.figure(figsize=(10, 5))</code>. This determines the dimensions
of the plot. Next, the closing prices are plotted. The
<code>plot()</code> function is used multiple times with different
subsets of the data to represent different periods: - The first
<code>plot()</code> function call represents the training period by
plotting the dates and corresponding adjusted close prices where the
dates are earlier than '2020-11-07'. - The second <code>plot()</code>
function call represents the testing period by plotting the dates and
adjusted close prices where the dates are greater than or equal to
'2020-11-07'. - The third <code>plot()</code> function call represents
the predicted prices during the testing period by plotting the dates and
the predicted closing prices. The <code>xlabel()</code> and
<code>ylabel()</code> functions are used to label the x-axis as 'Time'
and the y-axis as 'Closing Price', respectively. Lastly, the
<code>legend()</code> function is called to display a legend on the
graph, indicating the labels for the different lines representing the
training, testing, and predicted prices. By executing this code, a plot
is generated that shows the actual closing GOOG stock prices during
training and testing periods, as well as predicted closing prices. A
visual comparison of actual and predicted prices provides insight into
the model's performance.</p>
</div>
<div class="cell code" data-execution_count="46"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Xdol8v86bkj5" data-outputId="565a80ca-10b9-42e2-9f46-31b09ed48d85">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> math.sqrt(mean_squared_error(GOOG_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>), GOOG_prediction))</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> np.mean(np.<span class="bu">abs</span>(GOOG_prediction <span class="op">-</span> GOOG_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>))<span class="op">/</span>np.<span class="bu">abs</span>(GOOG_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>)))</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE: </span><span class="sc">{</span>rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MAPE: </span><span class="sc">{</span>mape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE: 115.66296805524927
MAPE: 0.039782693356206676
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>This code calculates the root mean squared error (RMSE) and mean
absolute percentage error (MAPE) between the predicted closing prices
(<code>GOOG_prediction</code>) and the actual closing prices
(<code>GOOG_Test_Y</code>) of the GOOG stock.</p>
<p>The first line of code calculates the RMSE by calling the
<code>mean_squared_error()</code> function, which measures the average
squared difference between the predicted and actual values. The
<code>sqrt()</code> function from the <code>math</code> module is then
used to compute the square root of the mean squared error, yielding the
RMSE value. In the second line of code, the MAPE is calculated by
computing the absolute difference between the predicted and actual
values. It then calculates the mean of the absolute differences divided
by the actual prices. This computes the average percentage difference
between the predicted and actual prices. The third and fourth lines of
code print the RMSE and MAPE values. The <code>f-string</code>
formatting is used to include the values within the printed strings. The
RMSE and MAPE values are computed and displayed, providing insights into
the model's accuracy and performance. A RMSE represents the average
magnitude of the prediction error, whereas a MAPE represents the average
percentage difference between the predicted and actual price.</p>
</div>
<div class="cell markdown" id="7QKWND5DTruk">
<p>Intuit</p>
</div>
<div class="cell code" data-execution_count="47"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:195}"
id="6qpItzGXT1gu" data-outputId="c31f0878-fe42-49f5-fee8-522a66c2efee">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>MSFT.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="47">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj. Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2015-01-02</td>
      <td>46.66</td>
      <td>47.42</td>
      <td>46.54</td>
      <td>46.76</td>
      <td>41.44</td>
      <td>27913900.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2015-01-05</td>
      <td>46.37</td>
      <td>46.73</td>
      <td>46.25</td>
      <td>46.33</td>
      <td>41.06</td>
      <td>39673900.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2015-01-06</td>
      <td>46.38</td>
      <td>46.75</td>
      <td>45.54</td>
      <td>45.65</td>
      <td>40.46</td>
      <td>36447900.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2015-01-07</td>
      <td>45.98</td>
      <td>46.46</td>
      <td>45.49</td>
      <td>46.23</td>
      <td>40.97</td>
      <td>29114100.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2015-01-08</td>
      <td>46.75</td>
      <td>47.75</td>
      <td>46.72</td>
      <td>47.59</td>
      <td>42.18</td>
      <td>29645200.0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown">
<p>This code displays the first few rows of the MSFT dataset, allowing
us to inspect the data and understand its structure and contents. This
is accomplished by calling the head() function on the MSFT dataset. The
default number of rows displayed is usually five, but it can be modified
by passing an argument to the <code>head()</code> function. This code
displays the column names and their values in the initial rows of the
dataset. Prior to performing further analysis or modeling, it is helpful
to understand the structure and types of data contained in the
dataset.</p>
</div>
<div class="cell code" data-execution_count="48"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="E3MHxY8bT7a5" data-outputId="3dba2670-166d-4a51-9383-09f8f115adde">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>MSFT.info()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1549 entries, 0 to 1548
Data columns (total 7 columns):
 #   Column      Non-Null Count  Dtype  
---  ------      --------------  -----  
 0   Date        1549 non-null   object 
 1   Open        1549 non-null   float64
 2   High        1549 non-null   float64
 3   Low         1549 non-null   float64
 4   Close       1549 non-null   float64
 5   Adj. Close  1549 non-null   float64
 6   Volume      1549 non-null   float64
dtypes: float64(6), object(1)
memory usage: 84.8+ KB
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>This code provides information about the MSFT dataset, such as the
column names, the number of non-null values, and the data types of each
column. It displays a summary of the dataset's metadata by calling the
info() function. This summary includes the index information, the column
names, the count of non-null values in each column, and the data types
of the columns. The code's purpose is to gain a high-level understanding
of the dataset. As a result, missing values can be identified,
appropriate data types can be determined for each column, and insights
can be gained into the overall quality and characteristics of the data.
Data preprocessing, exploratory data analysis, and modeling require this
information.</p>
</div>
<div class="cell code" data-execution_count="49" id="hYeHjmqGT8sh">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change Dtype of Date column</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>MSFT[<span class="st">&quot;Date&quot;</span>] <span class="op">=</span> pd.to_datetime(MSFT[<span class="st">&quot;Date&quot;</span>])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code converts the data type of the "Date" column in the MSFT
dataset to the datetime format. By using the
<code>pd.to_datetime()</code> function on the "Date" column of the MSFT
dataset, the values in that column are transformed from their original
data type (likely a string or object type) to the datetime data type
provided by the pandas library. The purpose of this code is to ensure
that the "Date" column is treated as datetime data, which allows for
convenient handling and manipulation of dates Time and date. Following
the conversion, the "Date" column can be used for various time-based
operations such as filtering, grouping, and time series analysis. When
working with temporal data, this conversion enables the use of pandas'
datetime functionality.</p>
</div>
<div class="cell markdown" id="KCrPxO3S6uPh">
<p>Split the Data into Training and Test set. The Training Period:
2015-01-02 - 2020-09-30 The Testing Period: 2020-10-01 - 2021-02-26</p>
</div>
<div class="cell code" data-execution_count="50" id="A10WQqexUJK2">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>MSFT_Date <span class="op">=</span> <span class="st">&#39;2020-10-01&#39;</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>MSFT_Train_X, MSFT_Train_Y, MSFT_Test_X, MSFT_Test_Y <span class="op">=</span> Dataset(MSFT, MSFT_Date)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code prepares the MSFT dataset for training and testing by
splitting it into input and target variables based on a specified
date.</p>
<p>The first line assigns the value '2020-10-01' to the variable
<code>MSFT_Date</code>, which represents the date used to split the
dataset into training and testing portions.</p>
<p>The second line calls the <code>Dataset()</code> function, passing
the MSFT dataset and the <code>MSFT_Date</code> as arguments. This
function performs the dataset splitting process. It divides the data
into four sets: <code>MSFT_Train_X</code>, <code>MSFT_Train_Y</code>,
<code>MSFT_Test_X</code>, and <code>MSFT_Test_Y</code>. -
<code>MSFT_Train_X</code> represents the input features (X) for the
training data, which are derived from the MSFT dataset prior to the
<code>MSFT_Date</code>. - <code>MSFT_Train_Y</code> represents the
corresponding target variable (Y) for the training data. -
<code>MSFT_Test_X</code> represents the input features for the testing
data, which are derived from the MSFT dataset on or after the
<code>MSFT_Date</code>. - <code>MSFT_Test_Y</code> represents the
corresponding target variable for the testing data. The purpose of this
code is to partition the By dividing the MSFT dataset into training and
testing sets based on the specified date, the dataset can be used for
model training and evaluation. Machine learning models can be trained on
the historical data and evaluated on the unobserved future data using
the resulting sets.</p>
</div>
<div class="cell markdown" id="Vk8LE9OW1zco">
<p>Fitting the model</p>
</div>
<div class="cell code" data-execution_count="51" id="2b8w-sYTUTpq">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>MSFT_Model <span class="op">=</span> Model()</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code initializes a machine learning model for the MSFT dataset.
This code creates an instance of the <code>Model</code> class, which
represents a machine learning model. The specific architecture and
configuration of the model are defined in the <code>Model</code>
function, which is typically a custom function based on the requirements
of the problem.</p>
<p>To train and predict, this code will instantiate a model object.
Layers, activation functions, and parameters specific to the problem can
be incorporated into the model. Using the available data, the model
object can then be configured and trained.</p>
</div>
<div class="cell code" data-execution_count="52" id="Aav5PTMSUYzx">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>MSFT_Model.<span class="bu">compile</span>(optimizer <span class="op">=</span> tf.keras.optimizers.Adam(), loss <span class="op">=</span> <span class="st">&#39;mse&#39;</span>, metrics <span class="op">=</span> tf.keras.metrics.RootMeanSquaredError())</span></code></pre></div>
</div>
<div class="cell markdown">
<p>In this code, the MSFT model is configured for the training process
by specifying the optimizer, loss function, and evaluation metrics. By
calling the compile() method, all of the necessary components are set
up.</p>
<p>Training algorithms are defined by the optimization algorithm
argument. In this case, the Adam optimizer is chosen, which is a popular
algorithm for gradient-based optimization. During training, the
difference between predicted and actual values is determined by the loss
function. In this case, the mean squared error (MSE) is chosen as the
loss function. The metrics argument defines the metrics that will be
computed and displayed during training. In this case, the root mean
squared error (RMSE) is chosen as the evaluation metric. If this code is
executed, the MSFT_Model will be configured with the appropriate
optimizer, loss function, and evaluation metric. In training iterations,
these settings guide the model's learning and assess its
performance.</p>
</div>
<div class="cell code" id="uMbnWIM9UhDx">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>MSFT_hist <span class="op">=</span> MSFT_Model.fit(MSFT_Train_X, MSFT_Train_Y, epochs <span class="op">=</span> <span class="dv">1000</span>, validation_data <span class="op">=</span> (MSFT_Test_X, MSFT_Test_Y), callbacks<span class="op">=</span>[callback])</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code trains the MSFT model using the training data and validates
its performance on the testing data. An instruction is given to the
MSFT_Model object, which instructs it to train using the input features
MSFT_Train_X and target variables MSFT_Train_Y. The specified number of
<code>epochs</code> determines the number of times the model will
iterate over the training data.</p>
<p>During the training process, the model's performance is evaluated on
the validation data provided as <code>validation_data</code>, which
consists of the input features <code>MSFT_Test_X</code> and the
corresponding target variables <code>MSFT_Test_Y</code>. This validation
data allows the model to assess its generalization and performance on
unseen data. An optional callbacks argument can be provided to provide
additional functionality. In this case, the <code>callback</code>
function is passed as a callback object, which can perform specific
actions at various points during training, such as adjusting the
learning rate or saving the best model weights.</p>
<p>By executing this code, the <code>MSFT_Model</code> is trained on the
training data for the specified number of epochs, and its performance is
monitored on the validation data. By learning patterns and relationships
within the training data, the model can make predictions, and through
the training process, the loss function is minimized. MSFT_hist contains
the training history, including loss and metrics for each epoch, which
can be analyzed and visualized.</p>
</div>
<div class="cell code" data-execution_count="54" id="E9ztdmCqUrec">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>history_dict <span class="op">=</span> MSFT_hist.history</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> history_dict[<span class="st">&quot;loss&quot;</span>]</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;root_mean_squared_error&quot;</span>]</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>val_loss <span class="op">=</span> history_dict[<span class="st">&quot;val_loss&quot;</span>]</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>val_root_mean_squared_error <span class="op">=</span> history_dict[<span class="st">&quot;val_root_mean_squared_error&quot;</span>]</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(loss) <span class="op">+</span> <span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code extracts the training history metrics from the
<code>MSFT_hist</code> object and assigns them to individual variables.
It contains a dictionary containing the training history metrics for
each epoch. The first line of the code assigns this dictionary to the
variable <code>history_dict</code>. Next, the code retrieves specific
metrics from the <code>history_dict</code> dictionary and assigns them
to separate variables: - The <code>loss</code> variable stores the
training loss values for each epoch. - The
<code>root_mean_squared_error</code> variable stores the training root
mean squared error (RMSE) values for each epoch. - The
<code>val_loss</code> variable stores the validation loss values for
each epoch. - The <code>val_root_mean_squared_error</code> A variable
called epochs stores the validation RMSE values for each epoch. The last
line of code defines epochs as a range of integers from 1 to the length
of the loss list plus 1. Training history metrics are plotted using this
range as the x-axis.</p>
<p>By executing this code, the training history metrics are extracted
and stored in separate variables, enabling further analysis,
visualization, and interpretation of the model's performance during
training and validation.</p>
</div>
<div class="cell code" data-execution_count="55"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:335}"
id="zp60IGaqUw7-" data-outputId="d8db879c-2cc7-4c8d-fc69-11cc89b8098d">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>fig.set_figheight(<span class="dv">5</span>)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>fig.set_figwidth(<span class="dv">15</span>)</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, loss, label <span class="op">=</span> <span class="st">&quot;Training Loss&quot;</span>)</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs, val_loss, label <span class="op">=</span> <span class="st">&quot;Validation Loss&quot;</span>)</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>ax1.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Training Root Mean Squared Error&quot;</span>)</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs, val_root_mean_squared_error, label <span class="op">=</span> <span class="st">&quot;Validation Root Mean Squared Error&quot;</span>)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>ax2.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="st">&quot;Epochs&quot;</span>, ylabel <span class="op">=</span> <span class="st">&quot;Loss&quot;</span>)</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/b2b103b9fb6edfbd31cc2c382c2cb080ae1ea444.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>This code plots the training and validation loss, as well as the
training and validation root mean squared error (RMSE), over the course
of the training epochs. The first line of code creates a figure object
<code>fig</code> with two subplots (<code>ax1</code> and
<code>ax2</code>) arranged side by side. The next two lines set the
dimensions of the figure using <code>set_figheight()</code> and
<code>set_figwidth()</code> functions, adjusting the height to 5 units
and the width to 15 units. The subsequent lines plot the training and
validation The loss on ax1 and the RMSE for training and validation on
ax2. Line plots are created using the plot() function, with epochs
serving as the x-axis values, and metrics (loss, val_loss,
root_mean_squared_error, val_root_mean_squared_error) as the y-axis
values. The <code>label</code> parameter is set to provide a label for
each line. Additional formatting is applied to each subplot using the
<code>set()</code> function to set the x-axis label
(<code>xlabel</code>), y-axis label (<code>ylabel</code>), and to
customize the appearance of the plot. The <code>legend()</code> function
is called on each subplot to display a legend that identifies the
plotted lines. Finally, <code>plt.show()</code> is used to display the
figure with the plotted metrics. By executing this code, a figure with
two subplots is shown, where Ax1 displays the training and validation
loss curves, and ax2 displays the training and validation RMSE curves.
When training and evaluating the model, this visual representation helps
to understand its behavior and convergence.</p>
</div>
<div class="cell markdown" id="IzoKGAK71e2e">
<p>Predicting Microsoft's closing stock price</p>
</div>
<div class="cell code" data-execution_count="56" id="aIR_MW2PU0OX">
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>MSFT_prediction <span class="op">=</span> MSFT_Model.predict(MSFT_Test_X)</span></code></pre></div>
</div>
<div class="cell markdown">
<p>This code uses the trained <code>MSFT_Model</code> to make
predictions on the testing data <code>MSFT_Test_X</code>.</p>
<p>The <code>predict()</code> method is called on the
<code>MSFT_Model</code> object, with <code>MSFT_Test_X</code> as the
input data. The model takes the input data and generates predictions for
the target variable. Based on the patterns and relationships it has
learned throughout training, it uses this code to predict the target
variable values for the testing data. MSFT_predictions store the results
of the prediction algorithm, which can then be analyzed or used for
evaluation.</p>
</div>
<div class="cell code" data-execution_count="57"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:351}"
id="h5tqUN3xU6m6" data-outputId="f2c2ff1c-da54-4acd-fe0d-ced11a0f2193">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>plt.plot(MSFT[<span class="st">&#39;Date&#39;</span>][MSFT[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-10-12&#39;</span>], MSFT[<span class="st">&#39;Adj. Close&#39;</span>][MSFT[<span class="st">&#39;Date&#39;</span>] <span class="op">&lt;</span> <span class="st">&#39;2020-10-12&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Training&#39;</span>)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>plt.plot(MSFT[<span class="st">&#39;Date&#39;</span>][MSFT[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-09&#39;</span>], MSFT[<span class="st">&#39;Adj. Close&#39;</span>][MSFT[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-09&#39;</span>], label <span class="op">=</span> <span class="st">&#39;Testing&#39;</span>)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>plt.plot(MSFT[<span class="st">&#39;Date&#39;</span>][MSFT[<span class="st">&#39;Date&#39;</span>] <span class="op">&gt;=</span> <span class="st">&#39;2020-10-12&#39;</span>], MSFT_prediction.reshape(<span class="op">-</span><span class="dv">1</span>), label <span class="op">=</span> <span class="st">&#39;Predictions&#39;</span>)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Time&#39;</span>)</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Closing Price&#39;</span>)</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>plt.legend(loc <span class="op">=</span> <span class="st">&#39;best&#39;</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="57">
<pre><code>&lt;matplotlib.legend.Legend at 0x7f967efd55d0&gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_448b08a3eb2f4090a28ac477796b947e/9ad657501eabae0826a5fa7843c18e43692c5c73.png" /></p>
</div>
</div>
<div class="cell markdown">
<p>This code generates a line plot to visualize the actual closing
prices, training data, testing data, and predicted values of the
Microsoft (MSFT) stock. The <code>plt.figure(figsize=(10, 5))</code>
line creates a new figure object with a specified width and height. The
subsequent lines use the <code>plt.plot()</code> function to create the
line plot: - The first <code>plt.plot()</code> line plots the actual
closing prices from the training period
(<code>MSFT['Date'] &lt; '2020-10-12'</code>) against the corresponding
dates, labeling it as "Training". - The second <code>plt.plot()</code>
line plots the actual closing prices from the testing period
(<code>MSFT['Date'] &gt;= '2020-10-09'</code>) against the corresponding
dates, labeling it as "Testing". - The third <code>plt.plot()</code>
line plots the predicted closing prices from the testing period
(<code>MSFT_prediction.reshape(-1)</code>) against the corresponding
dates, labeling it as "Predictions". The <code>plt.xlabel()</code> and
<code>plt.ylabel()</code> functions are used to set the x-axis and
y-axis labels to "Time" and "Closing Price", This function adds a legend
to the plot at the "best" location determined by the plot. Using this
code, a line plot is generated that shows MSFT stock closing prices,
training data, testing data, and predictions over time. Comparing the
predicted values with the actual data allows evaluating how well the
model captures the underlying patterns in stock prices.</p>
</div>
<div class="cell code" data-execution_count="58"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Q7U_uYv1U_Xf" data-outputId="046bcf3a-0f5c-459f-802d-c8379294e996">
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>rmse <span class="op">=</span> math.sqrt(mean_squared_error(MSFT_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>), MSFT_prediction))</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>mape <span class="op">=</span> np.mean(np.<span class="bu">abs</span>(MSFT_prediction <span class="op">-</span> MSFT_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>))<span class="op">/</span>np.<span class="bu">abs</span>(MSFT_Test_Y.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>)))</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;RMSE: </span><span class="sc">{</span>rmse<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;MAPE: </span><span class="sc">{</span>mape<span class="sc">}</span><span class="ss">&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>RMSE: 6.2306768444560205
MAPE: 0.02214984775145576
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>This code calculates two evaluation metrics, root mean squared error
(RMSE) and mean absolute percentage error (MAPE), to assess the
performance of the predictions made by the <code>MSFT_Model</code> on
the testing data.</p>
<p>The first line calculates the RMSE by comparing the predicted values
(<code>MSFT_prediction</code>) with the actual values of the testing
data (<code>MSFT_Test_Y.reshape(-1, 5)</code>) using the
<code>mean_squared_error()</code> function from the
<code>sklearn.metrics</code> module. The calculated mean squared error
is then passed to the <code>math.sqrt()</code> function to obtain the
RMSE.</p>
<p>As the second line shows, the MAPE is calculated by subtracting the
predicted values from the actual values, taking the absolute values of
the differences, dividing them by the absolute values of the actual
values, and then calculating their means. This function displays the
MAPE and RMSE calculated. The <code>f-string</code> syntax is employed
to include the values of <code>rmse</code> and <code>mape</code> within
the printed string. This code computes and prints the RMSE and MAPE
values, providing insights into the performance of the
<code>MSFT_Model</code>. Better predictive performance is indicated by
lower RMSE and MAPE values.</p>
</div>
</body>
</html>
